{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5E8v2cZ6Zkf"
   },
   "source": [
    "**Description:** This notebook demonstrates the application of PGD, PQN, PMGD, SOUL, and VI to the Bayesian latent space network model from Hoff et al. (2002). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XotQU1Ootpi6"
   },
   "source": [
    "# Latent space network model - Game of Thrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErKddtPzM3_H"
   },
   "source": [
    "First, we load the modules that we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRkQ4RDsIAGf",
    "outputId": "d1eb59f0-7eb0-43da-a2ba-ff43b2c01b07"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "# Numpy for computations.\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "# Pyplot for plots.\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains interactions between Games of Thrones characters during the first 4 seasons of the TV show. An edge exists between characters if they have interacted (i.e. spoken) with one another during that season of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_got import load_got\n",
    "from coinem.dataset import Dataset\n",
    "\n",
    "# Load GoT character interaction networks\n",
    "Y, names = load_got(seasons=[1,2,3,4], weight_min=10)\n",
    "y = jnp.asarray(Y[3])\n",
    "season = 'season_4'\n",
    "\n",
    "#Remove the rows and columns which contain only zero entries, i.e. degree=0\n",
    "names = names[np.where(np.sum(y,1)!=0)[0]]\n",
    "ytemp = np.delete(y,np.where(np.sum(y,1)==0),0)\n",
    "y = np.delete(ytemp,np.where(np.sum(ytemp,0)==0),1)\n",
    "Y =y\n",
    "data = Dataset(y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we model consist of an $D \\times D$ matrix Y, with each entry $y_{i,j}$ denoting the value of the relation from node $i$ to node $j$. We focus on binary-valued relations, although this could be extended to more general relations, e.g. count data or weighted networks. These extensions to more general relations are essentially alternative generalised linear models. Both directed and undirected relations can be analysed with the following model.\n",
    "\n",
    "We take a conditional independence approach to modeling by assuming that the presence or absence of a tie between two individuals (i.e. nodes) is independent of all other ties in the system, given the unobserved positions in social space of the two individuals,\n",
    "\n",
    "$P(Y|X,\\theta) = \\prod_{i \\neq j} P(y_{i,j}|x_{i,j},\\theta)$.\n",
    "\n",
    "A convenient model for $P(y_{i,j}|x_{i,j},\\theta)$ is the logistic regression model, where the probability of a tie between nodes $i$ and $j$ depends on the Euclidean distance between $x_i$ and $x_j$,\n",
    "\n",
    "$\\eta_{i,j} = \\mbox{log-odds}(y_{i,j}=1|x_i, x_j, \\theta) = \\alpha - ||x_i-x_j||.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coinem.dataset import Dataset\n",
    "from coinem.model import AbstractModel\n",
    "from jaxtyping import Array, Float\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GOTModel(AbstractModel):\n",
    "\n",
    "    def log_prob(self, latent: Float[Array, \"P D\"], theta: Float[Array, \"Q\"], data: Dataset) -> Float[Array, \"\"]:\n",
    "        \n",
    "        z = latent\n",
    "\n",
    "        #dist = jnp.matmul(z,z.T)/jnp.linalg.norm(z,axis=1)\n",
    "        dist = -jnp.sqrt(jnp.sum((z[None, :] - z[:, None])**2, -1)+10e-6)\n",
    "        \n",
    "        eta = theta + dist\n",
    "        log_prior =  -jnp.sum(jnp.dot(z.T,z))  \n",
    "        log_lik = jnp.sum(jnp.multiply(data.y.squeeze(), eta) - jnp.log1p(jnp.exp(eta)))\n",
    "        return log_lik + log_prior\n",
    "\n",
    "\n",
    "\n",
    "#log-target density p_theta(y,x)\n",
    "def log_target(th, z):\n",
    "    dist = jnp.sqrt(jnp.sum((z[None, :] - z[:, None])**2, -1)+10e-6)\n",
    "    eta = th - dist\n",
    "    log_prior =  -jnp.sum(jnp.dot(z.T,z))  \n",
    "    log_lik = jnp.sum(jnp.multiply(y,eta) - jnp.log1p(jnp.exp(eta)))\n",
    "    return log_lik + log_prior\n",
    "\n",
    "\n",
    "grad_theta = grad(log_target, 0)\n",
    "grad_x = grad(log_target,1)\n",
    "\n",
    "def procrustes_transform(X, mle):\n",
    "    Xtrans = np.copy(X)\n",
    "    N = np.shape(X)[0]\n",
    "    for i in range(N):\n",
    "        _, Xtrans[i,:,:], _ = procrustes(mle, X[i,:,:])    \n",
    "    return Xtrans\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rf35vq3IC7T"
   },
   "source": [
    "We then implement the algorithms. They take the following inputs:\n",
    "\n",
    "*   y : D x D adjacency matrix,\n",
    "*   h : step size parameter \n",
    "*   K : number of steps,\n",
    "*   N : number of particles,\n",
    "*   th : 1-dimensional vector with parameter guess,\n",
    "*   X : D x N matrix storing the initial particle cloud.\n",
    "\n",
    "The following inference algorithms return the following outputs:\n",
    "\n",
    "*   th : K-dimensional vector of parameter estimates,\n",
    "*   X : [D, 2, N]) matrix storing the particle clouds, assuming a 2-dimensional latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFb772_telnV"
   },
   "source": [
    "## Run the inference algorithms to learn $\\theta$ and the latent positions of the network nodes $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKT-6l_6urur"
   },
   "source": [
    "We start by running a simple gradient descent algorithm to find the maximum likelihood estimate for $\\theta$ and $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the MLE\n",
    "D = Y.shape[0]\n",
    "\n",
    "# Initialize parameter estimates and particle cloud, all at zero:\n",
    "key, x_key = random.split(key, 2)\n",
    "th = jnp.array([[1.0]])  # Parameter estimate.\n",
    "x = 0.1*random.normal(x_key,(D, 2))\n",
    "\n",
    "lr = 0.01\n",
    "for step in range(10000):\n",
    "    x_grad = grad_x(th,x)\n",
    "    x += lr*x_grad\n",
    "    th_grad = grad_theta(th,x) \n",
    "    th += lr*th_grad\n",
    "    if step % 1000 == 0:\n",
    "        print('Log_target', log_target(th,x))\n",
    "        print('theta',th)\n",
    "\n",
    "#Because reflections, rotations and translations of X will lead to the same likelihood value, so use a procrustean transformation X to a reference set X0.\n",
    "Xmle, _ ,_ = procrustes(random.normal(x_key,(D, 2)), x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the various algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WG-_AlQR_S_"
   },
   "outputs": [],
   "source": [
    "# Set approximation parameters:\n",
    "h = 1e-2 # Step-size. \n",
    "K = 500  # Number of steps.\n",
    "N = 10  # Number of particles.\n",
    "D = y.shape[0]\n",
    "\n",
    "X0 = 0.01*random.normal(key,(N, D, 2)) + Xmle[None, :]\n",
    "    \n",
    "# Run algorithms:\n",
    "\n",
    "model = GOTModel()\n",
    "\n",
    "from coinem.network_zoo import pgd, coin_svgd, soul\n",
    "\n",
    "th0 = jnp.array([[1.0]])  # Parameter estimate.\n",
    "\n",
    "# Run algorithms:\n",
    "z_pgd, th_pgd  = pgd(model, data, X0, th0, K, latent_step_size = 1e-3, theta_step_size = 1e-3)\n",
    "z_soul, th_soul  = soul(model, data, X0, th0, K, latent_step_size = 1e-3, theta_step_size = 1e-3)\n",
    "z_coin, th_coin = coin_svgd(model, data, X0, th0, K)\n",
    "\n",
    "#Procrustes transformation - post-processing step\n",
    "Z_pgd = procrustes_transform(z_pgd[-1], Xmle)\n",
    "Z_soul = procrustes_transform(z_soul[-1], Xmle)\n",
    "Z_coin = procrustes_transform(z_coin[-1], Xmle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the posterior mean estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coin EM (Fig. 5 and Fig. 19) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the latent positions for Coin\n",
    "import pandas as pd\n",
    "from adjustText import adjust_text\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "avg_Z_coin = jnp.mean(Z_coin,axis=0)\n",
    "\n",
    "clustering = DBSCAN(eps=0.003, min_samples=2).fit(avg_Z_coin)\n",
    "clusters = clustering.labels_+abs(min(clustering.labels_))\n",
    "\n",
    "indx = jnp.sum(y,1)>4\n",
    "plotting_index = np.where(indx*np.arange(D)!=0)[0]\n",
    "\n",
    "colormap = np.array(['#377eb8', '#ff7f00','#4daf4a','#f781bf','#a65628','#984ea3','#999999','#e41a1c','#dede00'])\n",
    "plt.scatter(avg_Z_coin[plotting_index,0],avg_Z_coin[plotting_index,1],c=colormap[clusters[plotting_index]])\n",
    "\n",
    "force_points =1\n",
    "texts = []\n",
    "for x_pos, y_pos, s in zip(avg_Z_coin[plotting_index,0], avg_Z_coin[plotting_index,1], names[plotting_index]):\n",
    "    texts.append(plt.text(x_pos, y_pos, s, size=9))\n",
    "\n",
    "adjust_text(texts, force_points=0.001, arrowprops=dict(arrowstyle=\"-\", color=\"k\", lw=0.5))\n",
    "plt.savefig('got_network_latent_variables_'+season+'_coin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PGD (Fig. 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the latent positions for PGD\n",
    "\n",
    "avg_Z_pgd = jnp.mean(Z_pgd,axis=0)\n",
    "\n",
    "clustering = DBSCAN(eps=0.003, min_samples=2).fit(avg_Z_pgd)\n",
    "clusters = clustering.labels_+abs(min(clustering.labels_))\n",
    "\n",
    "indx = jnp.sum(y,1)>4\n",
    "plotting_index = np.where(indx*np.arange(D)!=0)[0]\n",
    "\n",
    "\n",
    "colormap = np.array(['#377eb8', '#ff7f00','#4daf4a','#f781bf','#a65628','#984ea3','#999999','#e41a1c','#dede00'])\n",
    "plt.scatter(avg_Z_pgd[plotting_index,0],avg_Z_pgd[plotting_index,1],c=colormap[clusters[plotting_index]])\n",
    "\n",
    "force_points =1\n",
    "texts = []\n",
    "for x_pos, y_pos, s in zip(avg_Z_pgd[plotting_index,0], avg_Z_pgd[plotting_index,1], names[plotting_index]):\n",
    "    texts.append(plt.text(x_pos, y_pos, s, size=9))\n",
    "\n",
    "adjust_text(texts, force_points=0.001, arrowprops=dict(arrowstyle=\"-\", color=\"k\", lw=0.5))\n",
    "plt.savefig('got_network_latent_variables_'+season+'_pgd.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOUL (Fig. 21) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the latent positions for Soul\n",
    "\n",
    "avg_Z_soul = jnp.mean(Z_soul,axis=0)\n",
    "\n",
    "clustering = DBSCAN(eps=0.003, min_samples=2).fit(avg_Z_soul)\n",
    "clusters = clustering.labels_+abs(min(clustering.labels_))\n",
    "\n",
    "indx = jnp.sum(y,1)>4\n",
    "plotting_index = np.where(indx*np.arange(D)!=0)[0]\n",
    "\n",
    "colormap = np.array(['#377eb8', '#ff7f00','#4daf4a','#f781bf','#a65628','#984ea3','#999999','#e41a1c','#dede00'])\n",
    "plt.scatter(avg_Z_soul[plotting_index,0],avg_Z_soul[plotting_index,1],c=colormap[clusters[plotting_index]])\n",
    "\n",
    "force_points =1\n",
    "texts = []\n",
    "for x_pos, y_pos, s in zip(avg_Z_soul[plotting_index,0], avg_Z_soul[plotting_index,1], names[plotting_index]):\n",
    "    texts.append(plt.text(x_pos, y_pos, s, size=9))\n",
    "\n",
    "adjust_text(texts, force_points=0.001, arrowprops=dict(arrowstyle=\"-\", color=\"k\", lw=0.5))\n",
    "plt.savefig('got_network_latent_variables_'+season+'_soul.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6woA0pl4fEaB"
   },
   "source": [
    "We can also plot the parameter estimates $\\theta_t$ as a function of the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "R1XfFt7HfPDQ",
    "outputId": "bb276909-3f43-4350-9925-e979e4997560"
   },
   "outputs": [],
   "source": [
    "#plt.plot(th_vi, label='VI')\n",
    "plt.plot(th_pgd[:,:,1], label='PGD', zorder=5, color=\"C2\")\n",
    "plt.plot(th_soul[:,:,1], label='SOUL', zorder=1, color=\"C3\")\n",
    "plt.plot(th_coin[:,:,1], label='Coin EM', zorder=10, color=\"C0\")\n",
    "plt.xlabel('Iterations', fontsize=18)\n",
    "plt.ylabel(r'$\\theta$', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('got_network_theta_'+season+'.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_m1",
   "language": "python",
   "name": "venv_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
